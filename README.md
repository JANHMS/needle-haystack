---
layout: integration
name: Needle Haystack
description: Build RAG Haystack pipelines with Needle
authors:
  - name: needle-ai.com
pypi: https://pypi.org/project/needle-python/
repo: https://github.com/JANHMS/needle-haystack
sdk: https://github.com/oeken/needle-python
sdk-pypi: https://pypi.org/project/needle-python/
type: RAG as a Service
report_issue: https://github.com/Needle-ai/needle-python/issues
logo: /logos/needle-logo.png
version: Haystack 2.0
toc: true
---

# Needle Haystack Integration

### **Table of Contents**

- [Installation](#installation)
- [Usage](#usage)

## Installation

This project resides in the Python Package Index (PyPI), so it can easily be installed with `pip`:

```console
pip install needle-haystack
```

## Usage

The Needle Haystack integration provides components for working with the Needle API. These components can be used to create collections, add files to collections, and perform searches.

### Configure your API keys

- Get your `NEEDLE_API_KEY` from [Developer settings](https://needle-ai.com/dashboard/settings/developer).

```
os.environ["NEEDLE_API_KEY"] = ""
```

- Get OpenAPI key from [OpenAI](https://platform.openai.com/)

```
os.environ["OPENAI_API_KEY"] = ""
```

### Create a Collection in Needle and add Files

```python
from needle_haystack import NeedleDocumentStore
from haystack.utils import Secret

# If not provided a new collection is generated, otherwise an existing collection is used.
# You can see your collections at https://needle-ai.com/dashboard/collections/
document_store = NeedleDocumentStore(api_key=Secret.from_env_var("NEEDLE_API_KEY"), name="TechRadarCollection", collection_id='YOUR-COLLECTION-ID')

# Add files to your NeedleDocumentStore.
file_urls = {
    "tech-radar-30.pdf": "https://www.thoughtworks.com/content/dam/thoughtworks/documents/radar/2024/04/tr_technology_radar_vol_30_en.pdf"
}
document_store.write_documents(file_urls=file_urls)
```

### Search your collection

```python
from haystack import Pipeline
from haystack.utils import Secret
from haystack.components.generators import OpenAIGenerator
from haystack.components.builders import PromptBuilder  # Correct import for PromptBuilder
from needle_haystack import NeedleRetriever

retriever = NeedleRetriever(document_store=document_store)

# Set up a prompt template for the PromptBuilder
prompt_template = """
Given the following retrieved documents, generate a concise and informative answer to the query:

Query: {{query}}
Documents:
{% for doc in documents %}
    {{ doc.content }}
{% endfor %}

Answer:
"""

# Initialize the PromptBuilder
prompt_builder = PromptBuilder(template=prompt_template)

# Initialize the OpenAIGenerator with the API key
llm = OpenAIGenerator(api_key=Secret.from_env_var("OPENAI_API_KEY"))

# Build the pipeline
basic_rag_pipeline = Pipeline()
basic_rag_pipeline.add_component("retriever", retriever)
basic_rag_pipeline.add_component("prompt_builder", prompt_builder)
basic_rag_pipeline.add_component("llm", llm)

# Connect the components
basic_rag_pipeline.connect("retriever", "prompt_builder.documents")
basic_rag_pipeline.connect("prompt_builder", "llm")

# Define the query
question = "What techniques moved to adopt?"

# Run the full pipeline
result = basic_rag_pipeline.run({
    "retriever": {"text": question},
    "prompt_builder": {"query": question}
})

# Print the final result generated by the LLM
print("Final generated result:")

print(result['llm']['replies'][0])
```
